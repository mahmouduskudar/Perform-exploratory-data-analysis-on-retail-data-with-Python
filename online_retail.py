# -*- coding: utf-8 -*-
"""online_retail.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12MrrKOhT36mG4mDOreMVvoBaNSyWANk9

# Portfolio Project: Online Retail Exploratory Data Analysis with Python

## Overview

In this project, you will step into the shoes of an entry-level data analyst at an online retail company, helping interpret real-world data to help make a key business decision.

## Case Study
In this project, you will be working with transactional data from an online retail store. The dataset contains information about customer purchases, including product details, quantities, prices, and timestamps. Your task is to explore and analyze this dataset to gain insights into the store's sales trends, customer behavior, and popular products.

By conducting exploratory data analysis, you will identify patterns, outliers, and correlations in the data, allowing you to make data-driven decisions and recommendations to optimize the store's operations and improve customer satisfaction. Through visualizations and statistical analysis, you will uncover key trends, such as the busiest sales months, best-selling products, and the store's most valuable customers. Ultimately, this project aims to provide actionable insights that can drive strategic business decisions and enhance the store's overall performance in the competitive online retail market.

## Project Objectives
1. Describe data to answer key questions to uncover insights
2. Gain valuable insights that will help improve online retail performance
3. Provide analytic insights and data-driven recommendations

## Dataset

The dataset you will be working with is the "Online Retail" dataset. It contains transactional data of an online retail store from 2010 to 2011. The dataset is available as a .xlsx file named `Online Retail.xlsx`. This data file is already included in the Coursera Jupyter Notebook environment, however if you are working off-platform it can also be downloaded [here](https://archive.ics.uci.edu/ml/machine-learning-databases/00352/Online%20Retail.xlsx).

The dataset contains the following columns:

- InvoiceNo: Invoice number of the transaction
- StockCode: Unique code of the product
- Description: Description of the product
- Quantity: Quantity of the product in the transaction
- InvoiceDate: Date and time of the transaction
- UnitPrice: Unit price of the product
- CustomerID: Unique identifier of the customer
- Country: Country where the transaction occurred

## Tasks

You may explore this dataset in any way you would like - however if you'd like some help getting started, here are a few ideas:

1. Load the dataset into a Pandas DataFrame and display the first few rows to get an overview of the data.
2. Perform data cleaning by handling missing values, if any, and removing any redundant or unnecessary columns.
3. Explore the basic statistics of the dataset, including measures of central tendency and dispersion.
4. Perform data visualization to gain insights into the dataset. Generate appropriate plots, such as histograms, scatter plots, or bar plots, to visualize different aspects of the data.
5. Analyze the sales trends over time. Identify the busiest months and days of the week in terms of sales.
6. Explore the top-selling products and countries based on the quantity sold.
7. Identify any outliers or anomalies in the dataset and discuss their potential impact on the analysis.
8. Draw conclusions and summarize your findings from the exploratory data analysis.

# **Load the Data**

# Import Required Libraries
"""

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
from tabulate import tabulate
from scipy import stats

"""# Load the Dataset"""

data = pd.read_excel('/content/Online Retail.xlsx')

"""# Discover the Data

Print the shape of the dataset
"""

data.shape

"""Display the first few rows of the dataset"""

data.head()

"""Display the last few rows of the dataset"""

data.tail()

"""Display information about the dataset"""

data.info()

"""Display basic statistics of the dataset"""

data.describe()

"""Check for missing values in the dataset"""

data.isnull().sum()

"""Check for negative quantities in the dataset"""

negative = data['Quantity'] < 1
print("Number of negative quantities:", negative.sum())

"""# Check for cancelled orders in the dataset"""

cancelled = data['InvoiceNo'].str.contains('C', na=False)
print("Number of cancelled orders:", cancelled.sum())

"""Calculate the number of unknown negative orders"""

Unknown_neg = negative.sum() - cancelled.sum()
print("Number of unknown negative orders:", Unknown_neg)

"""Show Unique (Transction - Product - Customer - Country)"""

print("Number of transactions: ", data['InvoiceNo'].nunique())
print("Number of products: ",data['StockCode'].nunique())
print("Number of customers:", data['CustomerID'].nunique() )
print("Percentage of Null customers ID: ", round(data['CustomerID'].isnull().sum() * 100 / len(data), 2),"%")
print('Number of countries: ',data['Country'].nunique())

"""Calculate the number of Duplicated orders"""

data.duplicated(keep = False, subset = data.columns).sum()

"""Calculate the percentage of cancelled orders"""

print("We have ", cancelled.sum(), " cancelled orders.")

#percentage of cancellations
total_orders = len(data)
print('Percentage of orders Cancelled: {}/{} ({:.2f}%) '.format(cancelled.sum(), total_orders, cancelled.sum()/total_orders*100))

"""Calculate the percentage of unknown negative orders"""

print("We have ", Unknown_neg, " Unknown state orders.")

#percentage of Unknown state orders
print('Percentage of orders that have negative Quantity value but not cancelled: {}/{} ({:.2f}%) '.format(Unknown_neg, total_orders, Unknown_neg/total_orders*100))

"""# **Clean & Validate the Data**

# Clean Duplicated and Missing Values

Drop fully duplicated rows while keeping the first occurrence
"""

data = data.drop_duplicates(keep = 'first', subset = data.columns)

"""Drop rows where UnitPrice is less than or equal to 0"""

data = data[data['UnitPrice'] > 0]

"""Fill Empty 'CustomeID' Cells with Unknown Value"""

data['CustomerID'].fillna("Unknown", inplace=True)

"""# Create State Column

Create the 'State' column based on the specified conditions
"""

# Add a new column "State" to the DataFrame initialized with an empty string
data['State'] = ""

# Create a mask to identify potential returns (negative quantity)
returns_mask = data['Quantity'] < 0

# Create a temporary column to facilitate matching (optional)
data['AbsQuantity'] = data['Quantity'].abs()

# Reset index to preserve the original indices
data = data.reset_index().rename(columns={'index': 'OriginalIndex'})

# Initialize valid_pairs as an empty DataFrame
valid_pairs = pd.DataFrame()

# Merge the DataFrame with itself to find matching orders and returns
merged = data.merge(data, on=['StockCode', 'UnitPrice', 'CustomerID', 'AbsQuantity'], suffixes=('_order', '_return'))

# Filter the merged DataFrame to include only valid pairs (order-quantity positive and return-quantity negative)
valid_pairs = merged[(merged['Quantity_order'] > 0) & (merged['Quantity_return'] < 0)]

# Reset index of valid_pairs
valid_pairs.reset_index(drop=True, inplace=True)

"""Update the State column for orders and returns"""

data.loc[data['OriginalIndex'].isin(valid_pairs['OriginalIndex_order']), 'State'] = "Processed"
data.loc[data['OriginalIndex'].isin(valid_pairs['OriginalIndex_return']), 'State'] = "Returned"

# Mark the remaining positive Quantity orders as "Completed"
data.loc[(data['Quantity'] > 0) & (data['State'] == ""), 'State'] = "Completed"

# Remove the temporary column and reset the index back to original
data.drop(columns=['AbsQuantity'], inplace=True)
data.set_index('OriginalIndex', inplace=True)

data.rename_axis('ID', inplace=True)

"""Fill blank values in 'State' column based on StockCode values"""

# Define a mapping dictionary for StockCode values
mapping = {
    'D': 'Other Expenses',
    'S': 'Other Expenses',
    'AMAZONFEE': 'Other Expenses',
    'BANK CHARGES': 'Other Expenses',
    'CRUK': 'Other Expenses',
    'M': 'Other Expenses',
    'POST': 'Other Expenses'
}

data.loc[data['State'].str.strip() == '', 'State'] = data.apply(lambda row: mapping.get(row['StockCode'], 'Returned') if str(row['State']).strip() == '' else row['State'], axis=1)

"""# Create 'Gross" Column

Calculate the gross amount for each transaction (Quantity * UnitPrice)
"""

data = data.assign(Gross = data['Quantity'] * data['UnitPrice'])

"""# **Prepare Data to Visualization**

# Aggregating the data
"""

# Calculate the count of completed orders and returned items
completed_count = (data['State'] == 'Completed').sum()
returned_count = (data['State'] == 'Returned').sum()

# Adding a column for Month-Year
data['MonthYear'] = data['InvoiceDate'].dt.to_period('M')
# Adding a column for Day of the Week
data['Weekday'] = data['InvoiceDate'].dt.day_name()
#Adding a column for Hour of the Day
data['HourDay'] = data['InvoiceDate'].dt.hour

# Filter out rows where CustomerID is "Unknown"
data_filtered = data[data['CustomerID'] != 'Unknown']

# Filter out rows where State is "Completed"
completed_orders = data[data['State'] == 'Completed']

# Group by Country and count the number of unique CustomerIDs
customers_by_country = data.groupby('Country')['CustomerID'].nunique().reset_index()

# Exclude customers from the United Kingdom
customers_by_country_excluding_uk = customers_by_country[customers_by_country['Country'] != 'United Kingdom']

# Group by Country and count the number of unique InvoiceNos
purchases_by_country = data.groupby('Country')['InvoiceNo'].nunique().reset_index()

# Exclude purchases from the United Kingdom
purchases_by_country_excluding_uk = purchases_by_country[purchases_by_country['Country'] != 'United Kingdom']

# Group by CustomerID and count the number of unique InvoiceNo for each customer
purchases_by_customer = data_filtered.groupby('CustomerID')['InvoiceNo'].nunique().reset_index()
purchases_by_customer.columns = ['CustomerID', 'TotalPurchases']

# Group by CustomerID and sum the gross revenue for each customer
gross_by_customer = data_filtered.groupby('CustomerID')['Gross'].sum().reset_index()
gross_by_customer.columns = ['CustomerID', 'TotalGross']

# Select the top 50 customers by total purchases
top_50_purchases = purchases_by_customer.sort_values(by='TotalPurchases', ascending=False).head(50)

# Select the top 50 customers by total gross revenue
top_50_gross = gross_by_customer.sort_values(by='TotalGross', ascending=False).head(50)

# Group by CustomerID and calculate total purchases and gross revenue
customer_stats = data_filtered.groupby('CustomerID').agg(TotalPurchases = ('InvoiceNo', 'nunique'), TotalGross = ('Gross', 'sum')).reset_index()

# Sort by TotalPurchases and select the top 50 customers
top_50_customers = customer_stats.sort_values(by='TotalPurchases', ascending=False).head(50)

# Group by Description and calculate total purchases and gross revenue for completed orders
purchases_by_category = completed_orders.groupby('Description').agg(TotalPurchases=('InvoiceNo', 'nunique'), TotalGross=('Gross', 'sum')).reset_index()

# Group by Description and calculate total purchases and gross revenue for all orders
purchases_by_category_g = data.groupby('Description').agg(TotalPurchases=('InvoiceNo', 'nunique'), TotalGross=('Gross', 'sum')).reset_index()

# Select the top 20 categories by total gross revenue
top_categories = purchases_by_category_g.sort_values(by='TotalGross', ascending=False).head(20)

# Group by Quantity and count the number of unique InvoiceNos
purchases_by_quantity = completed_orders.groupby('Quantity')['InvoiceNo'].nunique().reset_index()

# Group by MonthYear and count the number of unique InvoiceNos
purchases_by_date = data.groupby('MonthYear')['InvoiceNo'].nunique().reset_index()
purchases_by_date['MonthYear'] = purchases_by_date['MonthYear'].astype(str)

# Group by MonthYear and sum the gross revenue
gross_by_month = data.groupby('MonthYear')['Gross'].sum().reset_index()
gross_by_month['MonthYear'] = gross_by_month['MonthYear'].astype(str)

# Group by Country and MonthYear and count the number of unique InvoiceNos
purchases_by_country_date = data.groupby(['Country', 'MonthYear'])['InvoiceNo'].nunique().reset_index()
purchases_by_country_date['MonthYear'] = purchases_by_country_date['MonthYear'].astype(str)

# Group by Weekday and count the number of unique InvoiceNos
purchases_by_weekday = data.groupby('Weekday')['InvoiceNo'].nunique().reset_index()

# Group by Weekday and sum the gross revenue
gross_by_weekday = data.groupby('Weekday')['Gross'].sum().reset_index()
gross_by_weekday['Weekday'] = gross_by_weekday['Weekday'].astype(str)

# Group by hour and calculate total gross revenue
gross_by_hour = data.groupby('HourDay')['Gross'].sum().reset_index()

"""# Print Value of Aggregated Data into Tables

Define a function to create text tables
"""

def create_text_table(dataframe, title):
    text_table = tabulate(dataframe, headers='keys', tablefmt='fancy_grid')
    text_table = f"\n{title}\n{text_table}\n"  # Add title to the table
    return text_table

"""Create a text table for the count of unique customers by country"""

customers_by_country_table = create_text_table(customers_by_country, "Customers by Country")
print(customers_by_country_table)

"""Create a text table for the count of unique purchases by country"""

purchases_by_country_table = create_text_table(purchases_by_country, "Purchases by Country")
print(purchases_by_country_table)

"""Create a text table for the count of unique purchases by customer"""

purchases_by_customer_table = create_text_table(purchases_by_customer, "Purchases by Customer")
print(purchases_by_customer_table)

"""Create a text table for the total gross revenue by customer"""

gross_by_customer_table = create_text_table(gross_by_customer, "Gross by Customer")
print(gross_by_customer_table)

"""Create a text table for the count of unique purchases by category"""

purchases_by_category_table = create_text_table(purchases_by_category, "Purchases by Category")
print(purchases_by_category_table)

"""Create a text table for the count of unique purchases by quantity"""

purchases_by_quantity_table = create_text_table(purchases_by_quantity, "Purchases by Quantity")
print(purchases_by_quantity_table)

"""Create a text table for the count of unique purchases by date"""

purchases_by_date_table = create_text_table(purchases_by_date, "Purchases by Date")
print(purchases_by_date_table)

"""Create a text table for the total gross revenue by month"""

gross_by_month_table = create_text_table(gross_by_month, "Gross by Month")
print(gross_by_month_table)

"""Create a text table for the count of unique purchases by weekday"""

purchases_by_weekday_table = create_text_table(purchases_by_weekday, "Purchases by Weekday")
print(purchases_by_weekday_table)

"""Create a text table for the total gross revenue by weekday"""

gross_by_weekday_table = create_text_table(gross_by_weekday, "Gross by Weekday")
print(gross_by_weekday_table)

"""Create a text table for the total gross revenue by hour of the day"""

gross_by_hour_table = create_text_table(gross_by_hour, "Gross by Hour")
print(gross_by_hour_table)

"""# **Visualization**

# Completed Orders to Returned Items
"""

sns.set(font_scale = 1.2)
plt.figure(figsize=(8,8))

# Create labels for the pie chart
labels = ['Completed', 'Returned']

# Create data for the pie chart
sizes = [completed_count, returned_count]

plt.pie(
    x = sizes,
    labels = labels,
    colors= ['green', 'red'],
    autopct='%1.2f%%',
    pctdistance=0.80,
)

### Add a hole in the pie
hole = plt.Circle((0, 0), 0.60, facecolor='white')
plt.title('Proportion of Completed Orders to Returned Items')
plt.gcf().gca().add_artist(hole)
plt.show()

"""# Number of Customers by Country (Log Scale)"""

plt.figure(figsize = (14, 7))
sns.barplot(data = customers_by_country, x = 'Country', y = 'CustomerID', palette = 'viridis', hue = 'Country', dodge = False, legend = False)
plt.yscale('log')
plt.xticks(rotation = 90, fontsize = 10)
plt.title('Number of Customers by Country (Log Scale)')
plt.xlabel('Country')
plt.ylabel('Number of Customers')
plt.show()

"""# Number of Customers by Country (Excluding UK)"""

plt.figure(figsize = (14, 7))
sns.barplot(data = customers_by_country_excluding_uk, x = 'Country', y = 'CustomerID', palette = 'viridis', hue = 'Country', dodge = False, legend = False)
plt.xticks(rotation = 90, fontsize = 10)
plt.title('Number of Customers by Country (Excluding UK)')
plt.xlabel('Country')
plt.ylabel('Number of Customers')
plt.show()

"""# Number of Purchases by Country (Log Scale)"""

# Original plot with UK included (log scale for y-axis)
plt.figure(figsize = (14, 7))
sns.barplot(data = purchases_by_country, x = 'Country', y = 'InvoiceNo', palette = 'viridis', hue = 'Country', dodge = False, legend = False)
plt.yscale('log')
plt.xticks(rotation = 90, fontsize = 10)
plt.title('Number of Purchases by Country (Log Scale)')
plt.xlabel('Country')
plt.ylabel('Number of Purchases')
plt.show()

"""# Number of Purchases by Country (Excluding UK)"""

plt.figure(figsize = (14, 7))
sns.barplot(data = purchases_by_country_excluding_uk, x = 'Country', y = 'InvoiceNo', palette = 'viridis', hue = 'Country', dodge = False, legend = False)
plt.xticks(rotation = 90, fontsize = 10)
plt.title('Number of Purchases by Country (Excluding UK)')
plt.xlabel('Country')
plt.ylabel('Number of Purchases')
plt.show()

"""# Distribution of Purchases by Customer (Top 50)"""

plt.figure(figsize = (14, 7))
sns.barplot(data = top_50_purchases, x = 'CustomerID', y = 'TotalPurchases', hue = 'CustomerID', palette = 'viridis', legend = False)
plt.xticks(rotation = 60, fontsize = 10)
plt.title('Top 50 Customers by Total Purchases')
plt.xlabel('CustomerID')
plt.ylabel('Total Purchases')
plt.show()

"""# Distribution of Gross by Customer (Top 50)"""

plt.figure(figsize=(14, 7))
sns.barplot(data = top_50_gross, x = 'CustomerID', y = 'TotalGross', hue = 'CustomerID', palette = 'viridis', legend = False)
plt.xticks(rotation = 60, fontsize = 10)
plt.title('Top 50 Customers by Total Gross Revenue')
plt.xlabel('CustomerID')
plt.ylabel('Total Gross Revenue')
plt.show()

"""# Top 50 Customers by Gross Purchases"""

# Prepare data for scatter plot
customer_ids = top_50_customers['CustomerID']
num_purchases = top_50_customers['TotalPurchases']
gross_purchases = top_50_customers['TotalGross']

# Plot scatter plot
plt.figure(figsize=(16, 8))
scatter = plt.scatter(customer_ids, gross_purchases, c = num_purchases, cmap = 'viridis', s = 100)

# Add color bar
plt.colorbar(scatter, label='Number of Purchases')

# Set labels and title
plt.xlabel('Customer ID')
plt.ylabel('Total Gross Purchases')
plt.title('Top 50 Gross Purchases')

# Show Customer IDs on x-axis
plt.xticks(rotation = 60, fontsize = 10)

# Show plot
plt.tight_layout()
plt.show()

"""# Top 20 Purchased Categories by Number of Purchases"""

plt.figure(figsize=(14, 7))
top_categories = purchases_by_category.sort_values(by='TotalPurchases', ascending=False).head(20)
sns.barplot(data = top_categories, x = 'TotalPurchases', y = 'Description', palette = 'viridis', hue = 'TotalPurchases', legend = False)
plt.title('Top 20 Purchased Categories')
plt.xlabel('Number of Purchases')
plt.ylabel('Category (Description)')
plt.yticks(fontsize = 10)
plt.show()

"""# Top 20 Purchased Categories by Total Gross"""

plt.figure(figsize=(14, 7))

# Plot the total gross for each category
sns.barplot(data = top_categories, x = 'TotalGross', y = 'Description', palette = 'viridis', hue = 'TotalGross', legend = False)

plt.title('Top 20 Purchased Categories by Total Gross')
plt.xlabel('Total Gross')
plt.ylabel('Category (Description)')
plt.yticks(fontsize = 10)
plt.show()

"""# Distribution of Purchases by Quantity"""

plt.figure(figsize=(22, 8))
sns.histplot(purchases_by_quantity['Quantity'], bins= 100, kde = True, color = 'green')
plt.title('Distribution of Purchases by Quantity')
plt.xlabel('Quantity')
plt.ylabel('Frequency')
plt.xticks(fontsize = 10)
plt.show()

"""# Monthly Purchases Number"""

plt.figure(figsize = (14, 7))
sns.lineplot(data = purchases_by_date, x = 'MonthYear', y = 'InvoiceNo', marker = 'o')
plt.title('Purchases by Date (Monthly)')
plt.xlabel('Month-Year')
plt.ylabel('Number of Purchases')
plt.xticks(rotation = 45, fontsize = 10)
plt.yticks(fontsize = 10)
plt.show()

"""# Monthly Gross"""

plt.figure(figsize = (14, 7))
sns.lineplot(data = gross_by_month, x = 'MonthYear', y = 'Gross', marker = 'o')
plt.title('Purchases by Date (Monthly)')
plt.xlabel('Month-Year')
plt.ylabel('Total Gross')
plt.xticks(rotation = 45, fontsize = 10)
plt.yticks(fontsize = 10)
plt.show()

"""# Monthly Orders and Gross Revenue"""

# Preparing data for radar chart
labels = purchases_by_date['MonthYear'].tolist()
num_vars = len(labels)

# Calculate angle of each axis
angles = np.linspace(0, 2 * np.pi, num_vars, endpoint=False).tolist()

# The radar chart is a circular graph, so we need to "complete the loop" by appending the first value to the end
labels += labels[:1]
angles += angles[:1]

# Data for orders by month
orders = purchases_by_date['InvoiceNo'].apply(np.log).tolist()
orders += orders[:1]

# Data for gross revenue by month with logarithmic transformation
gross = gross_by_month['Gross'].apply(np.log).tolist()  # using log1p to handle zero values
gross += gross[:1]

# Plotting the radar chart
fig, ax = plt.subplots(figsize=(10, 10), subplot_kw = dict (polar = True))

ax.fill(angles, orders, color='#9ac64d', alpha=0.25)
ax.plot(angles, orders, color='#9ac64d', linewidth=2, linestyle='solid', label='log(Orders) by Month')

ax.fill(angles, gross, color='#415d82', alpha=0.25)
ax.plot(angles, gross, color='#415d82', linewidth=2, linestyle='solid', label='Log(Gross Revenue) by Month')

# Adding labels and title
ax.set_yticklabels([])
ax.set_xticks(angles[:-1])
ax.set_xticklabels(labels[:-1])  # Remove the last appended label

# Rotate the chart by 90 degrees
ax.set_theta_offset(np.pi / 1.14)

plt.title('Monthly log(Orders and Gross Revenue)')
plt.legend(loc='upper right')
plt.show()

"""# Purchases by Weekdays"""

plt.figure(figsize=(14, 7))
order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
sns.barplot(data = purchases_by_weekday, x = 'Weekday', y = 'InvoiceNo', order =order, palette = 'viridis', hue = 'Weekday')
plt.title('Purchases by Weekdays')
plt.xlabel('Day of the Week')
plt.ylabel('Number of Purchases')
plt.xticks(fontsize = 10)
plt.yticks(fontsize = 10)
plt.show()

"""# Gross by Weekdays"""

plt.figure(figsize=(14, 7))
order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
sns.barplot(data = gross_by_weekday, x = 'Weekday', y = 'Gross', order =order, palette = 'viridis', hue = 'Weekday')
plt.title('Gross by Weekdays')
plt.xlabel('Day of the Week')
plt.ylabel('Total Gross')
plt.xticks(fontsize = 10)
plt.yticks(fontsize = 10)
plt.show()

# Preparing data for radar chart
labels = gross_by_weekday['Weekday'].tolist()
num_vars = len(labels)

# Calculate angle of each axis
angles = np.linspace(0, 2 * np.pi, num_vars, endpoint=False).tolist()

# The radar chart is a circular graph, so we need to "complete the loop" by appending the first value to the end
labels += labels[:1]
angles += angles[:1]

# Data for orders by month
orders = purchases_by_weekday['InvoiceNo'].apply(np.log).tolist()
orders += orders[:1]

# Data for gross revenue by month with logarithmic transformation
gross = gross_by_weekday['Gross'].apply(np.log).tolist()  # using log1p to handle zero values
gross += gross[:1]

# Plotting the radar chart
fig, ax = plt.subplots(figsize=(10, 10), subplot_kw = dict (polar = True))

ax.fill(angles, orders, color='#4b3b75', alpha=0.25)
ax.plot(angles, orders, color='#4b3b75', linewidth=2, linestyle='solid', label='log(Orders) by Day')

ax.fill(angles, gross, color='#347681', alpha=0.25)
ax.plot(angles, gross, color='#347681', linewidth=2, linestyle='solid', label='Log(Gross Revenue) by Day')

# Adding labels and title
ax.set_yticklabels([])
ax.set_xticks(angles[:-1])
ax.set_xticklabels(labels[:-1])  # Remove the last appended label

# Rotate the chart by 90 degrees
ax.set_theta_offset(np.pi / 2)

plt.title('Daily log(Orders and Gross Revenue)')
plt.legend(loc='upper right')
plt.show()

"""# Distribution of Purchases by Hour of the Day"""

plt.figure(figsize=(10, 6))
sns.countplot(data=data, x='HourDay', palette='viridis', hue = "HourDay", legend = False)
plt.title('Distribution of Purchases by Hour of the Day')
plt.xlabel('Hour of the Day')
plt.ylabel('Number of Purchases')
plt.show()

"""# Gross Revenue by Hour of the Day"""

plt.figure(figsize=(10, 6))
sns.barplot(data=gross_by_hour, x='HourDay', y='Gross', palette='viridis', hue = "HourDay", legend = False)
plt.title('Gross Revenue by Hour of the Day')
plt.xlabel('Hour of the Day')
plt.ylabel('Total Gross Revenue')
plt.show()

"""# **outliers & anomalies in Dataset**

Statistical summary of data with outliers
"""

summary_with_outliers = data.describe()
print(tabulate(summary_with_outliers))

# Calculate the Z-Score for the 'Quantity' column
z_scores = stats.zscore(data['Gross'])

# Create a boolean mask to identify outliers (both positive and negative Z-scores)
threshold = 3
outlier_mask = abs(z_scores) > threshold

# Extract outliers from the DataFrame
outliers = data[outlier_mask]

without_outliers_online_retail = data[~outlier_mask]

# Statistical Summary of data without outliers
summary_without_outliers = without_outliers_online_retail.describe()

print(tabulate(summary_without_outliers))

"""Statistical summary of data with outliers"""

# Drop the "count" row from the statistical summary
summary_without_count = summary_with_outliers.drop(index='count')

# Select numerical columns for the heatmap
numerical_columns = summary_without_count.select_dtypes(include=[np.number])

# Plot the heatmap using only numerical columns
plt.figure(figsize=(12, 6))
sns.heatmap(numerical_columns, annot=True, cmap='viridis', fmt='.2f')
plt.title('Statistical Summary with Outliers')
plt.show()

"""Statistical summary of data without outliers"""

# Drop the "count" row from the statistical summary
summary_without_count = summary_without_outliers.drop(index='count')

# Select numerical columns for the heatmap
numerical_columns = summary_without_count.select_dtypes(include=[np.number])

# Plot the heatmap using only numerical columns
plt.figure(figsize=(12, 6))
sns.heatmap(numerical_columns, annot=True, cmap='viridis', fmt='.2f')
plt.title('Statistical Summary without Outliers')
plt.show()

"""# **summarize**

In this analysis, we conducted several steps to clean, transform, analyze, and visualize the online retail data. Here’s a summary of what we accomplished:

**Data Preparation and Cleaning**

1. Loaded Data:

    . Imported the dataset and converted relevant columns to appropriate data types for analysis.

2. Handled Missing Values:

    .Filtered out rows where CustomerID or State were marked as "Unknown".

3. Created New Features:

    .Added MonthYear, Weekday, and HourDay columns to provide time-based features for analysis.

**Aggregations and Groupings**
4. Order and Customer Analysis:

    . Calculated the number of completed and returned orders.

    . Grouped data by Country to get the unique number of customers (CustomerID) and the number of unique invoices (InvoiceNo).

    . Grouped data by CustomerID to compute total purchases and total gross revenue per customer.

    . Identified the top 50 customers based on total purchases and gross revenue.

5. Product and Category Analysis:

    . Grouped data by Description to get the total purchases and total gross revenue per product category.

    . Identified the top 20 categories based on total gross revenue.

6. Time-Based Analysis:

    . Grouped data by MonthYear to analyze monthly trends in orders and gross revenue.

    . Grouped data by Weekday to understand daily trends.

    . Grouped data by HourDay to study hourly trends in gross revenue.

**Outlier Detection and Removal**

7. Outlier Detection:

    . Used the Z-score method to identify outliers in the Gross revenue data.

    . Removed rows identified as outliers to create a dataset without outliers for further analysis.

8. Statistical Summaries:

    . Generated descriptive statistics for the dataset with and without outliers to compare the impact of outlier removal.

**Visualization**

9. Heatmaps:

    . Created heatmaps to visualize the statistical summaries of data with and without outliers.

10. Radar Chart:

    . Constructed a radar chart to compare monthly
    orders and logarithmic gross revenue, adjusting for the large discrepancy in scale between the two metrics.

    . Rotated the radar chart by some degrees to improve readability.

**Conclusions**

. Customer Insights:

    . Identified top customers who contribute
    significantly to the total gross revenue, highlighting the importance of
    customer segmentation and targeted marketing.

. Product Insights:

    . Determined top-selling product categories,
    which can guide inventory management and promotional strategies.

. Time-Based Insights:

    . Uncovered monthly, daily, and hourly trends in orders and revenue,
    which can inform timing for marketing campaigns and stock management.

. Outlier Impact:

    . Highlighted the importance of outlier detection and removal
    to provide a clearer view of the data distribution and central tendencies.

. Visualization:

    . Effective visualizations were created to facilitate the understanding of complex datasets,
    making it easier to derive actionable business insights.

This comprehensive analysis helps in understanding customer behavior, optimizing product offerings, and making data-driven decisions to enhance business performance.
"""